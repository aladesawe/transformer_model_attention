{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-2.0.0-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/anaconda3/lib/python3.11/site-packages (from pydot) (3.0.9)\n",
      "Downloading pydot-2.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pydot' has no attribute 'InvocationException'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pydot/core.py:1753\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     stdout_data, stderr_data, process \u001b[38;5;241m=\u001b[39m call_graphviz(\n\u001b[1;32m   1754\u001b[0m         program\u001b[38;5;241m=\u001b[39mprog,\n\u001b[1;32m   1755\u001b[0m         arguments\u001b[38;5;241m=\u001b[39marguments,\n\u001b[1;32m   1756\u001b[0m         working_dir\u001b[38;5;241m=\u001b[39mtmp_dir,\n\u001b[1;32m   1757\u001b[0m     )\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pydot/core.py:133\u001b[0m, in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m program_with_args \u001b[38;5;241m=\u001b[39m [program] \u001b[38;5;241m+\u001b[39m arguments\n\u001b[0;32m--> 133\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[1;32m    134\u001b[0m     program_with_args,\n\u001b[1;32m    135\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[1;32m    136\u001b[0m     cwd\u001b[38;5;241m=\u001b[39mworking_dir,\n\u001b[1;32m    137\u001b[0m     shell\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    138\u001b[0m     stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[1;32m    139\u001b[0m     stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    141\u001b[0m )\n\u001b[1;32m    142\u001b[0m stdout_data, stderr_data \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/subprocess.py:1022\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1020\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1022\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m   1023\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m   1024\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m   1025\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m   1026\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m   1027\u001b[0m                         errread, errwrite,\n\u001b[1;32m   1028\u001b[0m                         restore_signals,\n\u001b[1;32m   1029\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m   1030\u001b[0m                         start_new_session, process_group)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/subprocess.py:1899\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1898\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1899\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1900\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/utils/vis_utils.py:57\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Attempt to create an image of a blank graph\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# to check the pydot/graphviz installation.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     pydot\u001b[38;5;241m.\u001b[39mDot\u001b[38;5;241m.\u001b[39mcreate(pydot\u001b[38;5;241m.\u001b[39mDot())\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pydot/core.py:1762\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1761\u001b[0m     args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found in path.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(prog\u001b[38;5;241m=\u001b[39mprog)\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m num_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m self_attention(input_shape\u001b[38;5;241m=\u001b[39m(seq_length, key_dim),\n\u001b[1;32m     30\u001b[0m                     num_heads\u001b[38;5;241m=\u001b[39mnum_heads, key_dim\u001b[38;5;241m=\u001b[39mkey_dim)\n\u001b[0;32m---> 31\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself-attention.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rankdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBT\u001b[39m\u001b[38;5;124m'\u001b[39m, show_layer_activations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/utils/vis_utils.py:451\u001b[0m, in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations, show_trainable)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     )\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_graphviz():\n\u001b[1;32m    452\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must install pydot (`pip install pydot`) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand install graphviz \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor plot_model to work.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m     )\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython.core.magics.namespace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;66;03m# We don't raise an exception here in order to avoid crashing\u001b[39;00m\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;66;03m# notebook tests where graphviz is not available.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/utils/vis_utils.py:59\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     pydot\u001b[38;5;241m.\u001b[39mDot\u001b[38;5;241m.\u001b[39mcreate(pydot\u001b[38;5;241m.\u001b[39mDot())\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, pydot\u001b[38;5;241m.\u001b[39mInvocationException):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pydot' has no attribute 'InvocationException'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def self_attention(input_shape, prefix=\"att\", mask=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Self-attention layers at transformer encoder and decoder.\n",
    "    Assumes its input is the output from positional encoding layer.\n",
    "    Args:\n",
    "        prefix (str): The prefix added to the layer names\n",
    "        masked (bool): whether to use causal mask. Should be False on\n",
    "                    encoder and True on decoder. When True, a mask will be applied\n",
    "                    such that each location only has access to the locations before it.\n",
    "    \"\"\"\n",
    "    # create layers\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f\"{prefix}_in1\")\n",
    "    attention = tf.keras.layers.MultiHeadAttention(name=f\"{prefix}_attn1\", **kwargs)\n",
    "    norm = tf.keras.layers.LayerNormalization(name=f\"{prefix}_norm1\")\n",
    "    add = tf.keras.layers.Add(name=f\"{prefix}_add1\")\n",
    "    # functional API to connect input to output\n",
    "    attout = attention(query=inputs, value=inputs, key=inputs, use_causal_mask=mask)\n",
    "    outputs = norm(add([inputs, attout]))\n",
    "    # create model and return\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=f\"{prefix}_att\")\n",
    "    return model\n",
    "\n",
    "seq_length = 20\n",
    "key_dim = 128\n",
    "num_heads = 8\n",
    "\n",
    "model = self_attention(input_shape=(seq_length, key_dim),\n",
    "                    num_heads=num_heads, key_dim=key_dim)\n",
    "tf.keras.utils.plot_model(model, \"self-attention.png\", show_shapes=True, show_dtype=True, show_layer_names=True, rankdir='BT', show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def cross_attention(input_shape, context_shape, prefix=\"att\", **kwargs):\n",
    "    \"\"\"\n",
    "    Cross-attention layers at transformer decoder. Assumes its\n",
    "    input is the output from positional encoding layer at decoder\n",
    "    and context is the final output from encoder.\n",
    "    Args:\n",
    "        prefix (str): The prefix added to the layer names\n",
    "    \"\"\"\n",
    "    # create layers\n",
    "    context = tf.keras.layers.Input(shape=context_shape, dtype='float32', name=f\"{prefix}_ctx2\")\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f\"{prefix}_in2\")\n",
    "    attention = tf.keras.layers.MultiHeadAttention(name=f\"{prefix}_attn2\", **kwargs)\n",
    "    norm = tf.keras.layers.LayerNormalization(name=f\"{prefix}_norm2\")\n",
    "    add = tf.keras.layers.Add(name=f\"{prefix}_add2\")\n",
    "    # functional API to connect input to output\n",
    "    attout = attention(query=inputs, value=context, key=context)\n",
    "    outputs = norm(add([attout, inputs]))\n",
    "    # create model and return\n",
    "    model = tf.keras.Model(inputs=[(context, inputs)], outputs=outputs, name=f\"{prefix}_cross\")\n",
    "    return model\n",
    "\n",
    "\n",
    "seq_length = 20\n",
    "key_dim = 128\n",
    "num_heads = 8\n",
    "\n",
    "model = cross_attention(input_shape=(seq_length, key_dim), context_shape=(seq_length, key_dim), num_heads=num_heads, key_dim=key_dim)\n",
    "tf.keras.utils.plot_model(model, \"cross-attention.png\", show_shapes=True, show_dtype=True, show_layer_names=True, rankdir='BT', show_layer_activations=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
